1. Create env

2. activate env

3. create requirements.txt & install it. {dvc, dvc[gdrive], sklearn} modules should be there.

4. create a template.py file using "python > template.py" in terminal. Use template.py file to make necessary files & directories in main directory.
Also make a directory named "data_given" in root directory & put the dataset over there.

5. run following from terminal:
	5.1. git init
	5.2. dvc init
	5.3. dvc add data_given/winequality.csv
	5.4. git add .
	5.5. git commit -m "first commit"
	5.6. git branch -M main
	5.7. git remote add origin  https://github.com/ssr-1998/Wine_Quality_MLOPs.git
	5.8. git push origin main

6. write code in params.yaml file & push updates on github

7. create a python file in src directory named get_data.py & write code for reading data, process & then return it as dataframe. In this we will load the data using
params.yaml & return it to the system after loading in a dataframe format. In end, push updates on github

8. create a python file in src directory named load_data.py & write code for reading data from data source, process & then save the new csv file as a dataframe.
Mention this load_data.py as a stage in dvc.yaml file & run "dvc repro" in terminal. It will create a dvc.lock file which is having all the parts of stage 1 tracked.
In end, push updates on github

9. create a python file in src directory named split_data.py & write code for Spliting the Raw Data into [TRAIN & TEST] & then save the new csv files as a dataframe.
Mention this split_data.py as a stage in dvc.yaml file & run "dvc repro" in terminal. In end, push updates on github

10. create a python file in src directory named train_and_evaluate.py & write code for training model on train & test. Also write code for model evaluation.

11. create a report directory in main directory and create 2 json files with name storing params.json & score.json files.

12. before running check all code in train_and_evaluate.py, dvc.yaml & in params.yaml. If all good. run "dvc repro" means to reproduce. If all runs good. Push to GIT.

13. run "dvc metrics show" in terminal. This will show the current params & scores for model.

14. run "dvc metrics diff" in terminal. This will show the difference b\w the old & new params & scores.

|---|---|---|---|---|---|---|---|---|---|---|---|---|---| After this we are going for Testing Part |---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|

1. As using pytest & tox so will install them & add them in requirements.txt

2. make a file named "tox.ini" in main directory & mention the requriments & commands which we want for virtual environment which will be created by tox for testing.
Remember to use "tox.ini" file in .ini form & not to use it as a text file. As tox create a temporary virtual environment for us for testing only.

3.  make a directory named "tests" which will have all test casses & create 3 python files named "conftest.py", "test_config.py" & "__init__.py".

4.  In "test_config.py" whatever function we are going to make for testing purpose the name of function should start with "test".
--------------------------------------------------------------------------------------------------------------------------------
Note: assert is a function in python which is used in testing. It will print passed or failed for the given condition. For eg.
Suppose this is done in test_config.py:
	def test_generic():
		a = 4
		b = 4
		assert a==b
If the condition is true the assert function in test_generc function will print Passed. Else Failed.
--------------------------------------------------------------------------------------------------------------------------------

5. pytest -v (command for running test casses {Like test cases in conftest.py & etc..})

6. "tox" (command to run tox.ini file. When running 1st time it will install all requirements from requirements.txt, will create a virtual env & will run conftest.py
as well. From 2nd time it won't again install requirements or create any virtual env but will directly run test_config.py & other which we will specify in commands.)
--------------------------------------------------------------------------------------------------------------------------------------------------
Note:
	tox -r (If we made any changes in our requirements.txt file then to have those changes installed in tox env as well this command is used.)
---------------------------------------------------------------------------------------------------------------------------------------------------

7. Now in root directory make a file named "steup.py". We make this file to make a python file or function a python package. Which can be used in other projects too.
A package which can be pip installed & which could be imported anywhere on system. When we will do coding in this file then first we need to run "python install -e ."
in terminal for python to make "src" directory a package. Now, from "tox.ini" file we can remove "skipsdist=True".

8. Update all on Github.

9.{Only for this Project} Now, run "pip install jupyterlab" in env & run "jupyter-lab notebooks\".
Here make a ipynb file, there can experiment whatever we want. Like any kind of Analysis or anything.

10. In ipynb file. We made a custom error for our project. Which will raise error if User tries to submit any input beyond range specified for each input & made a
"schema_in.json" file storing all features minimum & maximum values.

11. Now, put that Custom Error in "test_config.py" & modify file according to need. If error is running good then will commit changes to Git.

12. Let's use "flake8" now. It is useful to show normal warnings which are there in Python files. Put "flake8" in "requirements.txt" & write code of "flake8" in 
"tox.ini" in "commands".

13. 
